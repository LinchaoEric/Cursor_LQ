- [Analytical Execution](#analytical-execution)
  - [What can you expect?](#what-can-you-expect)
  - [How to Prep](#how-to-prep)
    - [Aspects of the Analytical Execution questions include:](#aspects-of-the-analytical-execution-questions-include)
    - [You will **NOT** be asked the following:](#you-will-not-be-asked-the-following)
- [Fake Account](#fake-account)
  - [Context](#context)
  - [Exact Questions and Model Answers](#exact-questions-and-model-answers)
    - [**Question 1**](#question-1)
    - [**Question 2**](#question-2)
    - [**Question 3**](#question-3)
    - [**Question 4**](#question-4)
  - [Why These Questions Align with Metaâ€™s Analytical Execution](#why-these-questions-align-with-metas-analytical-execution)
  - [Key Takeaways for Candidates](#key-takeaways-for-candidates)
- [å‡æ–°é—»](#å‡æ–°é—»)
- [è¯„è®ºåˆ†å¸ƒ](#è¯„è®ºåˆ†å¸ƒ)
    - [**Comment Distribution Question**](#comment-distribution-question)
      - [**Context**](#context-1)
    - [**Question 1**](#question-1-1)
    - [**Question 2**](#question-2-1)
    - [**Question 3**](#question-3-1)
    - [**Question 4**](#question-4-1)
    - [**Question 5**](#question-5)
    - [**Bonus Question**](#bonus-question)
- [Feedé‡Œæ’å¹¿å‘Š](#feedé‡Œæ’å¹¿å‘Š)
    - [**Ads Impression Distribution Question**](#ads-impression-distribution-question)
      - [**Context**](#context-2)
    - [**Question 1**](#question-1-2)
    - [**Question 2**](#question-2-2)
    - [**Question 3**](#question-3-2)
    - [**Question 4**](#question-4-2)
    - [**Question 5**](#question-5-1)
    - [**Question 6**](#question-6)
    - [**Question 7**](#question-7)
    - [Question 8: **Probability of Users Seeing Back-to-Back Ads**](#question-8-probability-of-users-seeing-back-to-back-ads)
    - [**1. Scenario 1: Fixed Interval Ad Insertion**](#1-scenario-1-fixed-interval-ad-insertion)
    - [**2. Scenario 2: Random Ad Insertion**](#2-scenario-2-random-ad-insertion)
      - [**Probability Calculation**](#probability-calculation)
    - [**3. Example Calculation**](#3-example-calculation)
    - [**4. Summary**](#4-summary)
  - [When choosing an ad insertion strategy, balancing user experience and ad distribution fairness is crucial. Random insertion might lead to more back-to-back ads, potentially harming user experience.](#when-choosing-an-ad-insertion-strategy-balancing-user-experience-and-ad-distribution-fairness-is-crucial-random-insertion-might-lead-to-more-back-to-back-ads-potentially-harming-user-experience)
    - [**Takeaways**](#takeaways)

**[2024-10-28 Meta onsite å¥½åƒæ˜¯æ–°é¢˜](https://www.1point3acres.com/bbs/thread-1094505-1-1.html)**
AE: è§†é¢‘æ¨èå’Œåˆ†äº«ï¼ŒåŒ…å«ä¸¤é“æ¦‚ç‡é¢˜ã€‚
**[ã€meta voã€‘ ](https://www.1point3acres.com/bbs/thread-1102657-1-1.html)**
ae: ä¸€ä¸ªæœç´¢featureæ˜¯ä¸æ˜¯successfulæœ‰2ä¸ªdimensionæ¥è¯„ä¼°ï¼ˆrelevancy,accuracy)ï¼Œéƒ½æ˜¯binary flag (1/0). å‰é¢å‡ é—®å¾ˆç®€å•ï¼Œåé¢æœ‰ä¸€é—®æˆ‘ç­”çš„ä¸å¤ªå¥½ï¼ˆå…¬å¼è®°é”™äº†ï¼ŒğŸ˜¢ï¼‰ï¼Œè¯´æœ‰ä¸¤ä¸ªmodelåšçš„è¿™ä¸ªfeatureï¼Œå„è¢«100ä¸ªäººä½¿ç”¨ï¼ˆ1äºº1æ¬¡)ï¼Œä¸€ä¸ªæœ‰90äººåé¦ˆè¯´æ˜¯successfulï¼Œä¸€ä¸ªæœ‰85äººåé¦ˆsuccessfulï¼ˆæ•°å­—å¯èƒ½è®°å¾—ä¸å¯¹ï¼Œå°±è¿™ä¸ªæ„æ€ï¼‰ï¼Œèƒ½ä¸èƒ½è¯´ä¸€ä¸ªmodelå¼ºäºå¦ä¸€ä¸ªmodelï¼Ÿ ç”¨å·²çŸ¥çš„æ•°æ®validateã€‚
# Analytical Execution

## What can you expect?
In your Analytical Execution interview, your interviewer will assess your performance on 4 focus areas:

- **Creating Hypotheses**: Formulates assertions to test ideas that provide answers to business questions.
- **Quantitative Analysis**: Uses statistical code to carry out analyses ranging from correlations to multivariate analysis to measurement models.
- **Determining Goals & Success Metrics**: Identifies metrics that reflect operational success and inform business objectives.
- **Demonstrating Agility**: Proactively embraces change, manages through ambiguity, and is resilient in the face of challenges.

## How to Prep
In addition to reviewing the above information, these tips may be helpful as you prepare. 

### Aspects of the Analytical Execution questions include:
- Understanding hypotheses for launching new features.
- Considering and quantifying tradeoffs of a feature in terms of metrics.
- Elements of descriptive stats (mean/expected value, median, mode, percentiles).
- Common distributions such as binomial or normal distributions.
- The profile of real-world data.
- Law of Large Numbers, Central Limit Theorem, Linear Regression.
- Conditional probabilities, including Bayesâ€™ Theorem.

### You will **NOT** be asked the following:
- Advanced stats/math concepts: calculus or advanced statistical/ML models.
- More complex distributions like the exponential, Weibull, Beta, etc.
- Contrived estimation problems (i.e., â€œHow many golf balls fit in a 747â€).

--- 
[2024-11-28 ä¹°å®ƒ VO è¿‡ç»](https://www.1point3acres.com/bbs/thread-1100228-1-1.html)<br>
AE: Fake account - Straightforward Bayes' theorem questions with some questions about the metrics definition
[2024-02-22 Meta DSA VO](https://www.1point3acres.com/bbs/thread-1047008-1-1.html)  
ç»Ÿè®¡é—®é¢˜åå¤šï¼Œuser comment distributioné•¿ä»€ä¹ˆæ ·ï¼ˆç”»å›¾ï¼‰ï¼Œç„¶ååˆ†åˆ«æ ‡å‡ºmean, median, å’Œ95th percentileåœ¨å“ªé‡Œã€‚å¦‚æœæŠŠä¸€ä¸ªappçš„ç”¨æˆ·åˆ†æˆ10ä¸ªå°ç»„ï¼Œæ¯ä¸ªå°ç»„æœ‰10kç”¨æˆ·ï¼Œæ¯ä¸ªç»„åˆ†åˆ«çš„distributioné•¿ä»€ä¹ˆæ ·ï¼ˆè¿™é¢˜æˆ‘çŒœæ˜¯å…³äºcentral limit theorem? ). è¿˜é—®äº†standard deviationçš„å…¬å¼ã€‚ã€‚ã€‚ã€‚

[2024-11-23 ä¹°å®ƒæ–°é²œè·ªç» - DS - VO](https://www.1point3acres.com/bbs/thread-1099426-1-1.html)  
åœ°é‡Œçš„è€é¢˜ç›®äº†ï¼Œå¤§è‡´å¦‚ä¸‹
æ—¥æ´»ç”¨æˆ·çš„å¹³å‡è¯„è®ºå˜å¤šäº†ï¼Œ å› ä¸ºæœºå™¨äººè´¦æˆ·å‘äº†æ›´å¤šçš„è¯„è®ºã€‚ç®€å•è®¡ç®—æœ‰å¤šå°‘æœºå™¨äººã€‚ç„¶åè®¨è®ºäº†æ€ä¹ˆæ£€æµ‹æœºå™¨äººã€‚æ€ä¹ˆå»è¡¡é‡æ˜¯å¦æˆåŠŸï¼Œä»¥åŠæœ‰ä»€ä¹ˆå½±å“ã€‚

# Fake Account 
[2024-11-20 ä¹°å®ƒ VO æ–°é²œå‡ºç‚‰ ç»†èŠ‚+è®¨è®º+ç­‰ç»“æœ](https://www.1point3acres.com/bbs/thread-1098942-1-1.html)  
5% æ˜¯fake accountï¼Œfake accountå‘çš„ friend frequentæ˜¯authentic accountçš„10å€ï¼Œæ²¡åˆ«çš„ä¿¡æ¯äº†ã€‚  
1. P(fake|a friend request). Î§
2. P(at least one request is from fake account | 5 friend request)ï¼Œç®—å®Œé¢è¯•å®˜è·Ÿæˆ‘è·Ÿæˆ‘æ„Ÿæ…¨äº†ä¸‹fakeçš„accountè¿˜çœŸæ˜¯å¤šå•Šï¼æˆ‘è¯´æ˜¯å•Šã€‚ã€‚ã€‚
3. è¯´æœ‰classifierï¼Œç»™äº†TP AND FNéƒ½æ˜¯95%ï¼Œç„¶åç”¨è´å¶æ–¯ç®—ä¸€ä¸ªæ•°ã€‚å¥—å…¬å¼ä¸éš¾ã€‚ç®—å‡ºæ¥50%é—®æˆ‘è§‰å¾—è¿™ä¸ªclassifieræ€ä¹ˆæ ·ã€‚æˆ‘è¯´ä¸€èˆ¬ï¼Œå°±æ˜¯randomçš„åŸºæœ¬ä¸Šã€‚
4. åº”è¯¥çœ‹ä»€ä¹ˆmetricsã€‚æˆ‘æŠŠè·Ÿunbalanced data setçš„classifieræœ‰å…³çš„çŸ¥é“çš„éƒ½è¯´äº†ã€‚
æœ¬æ¥åªçœ‹äº†è¿‘æœŸçš„é¢˜ï¼Œé¢è¯•å‰å‡ å¤©åˆ·åˆ°äº†fake accountæ„Ÿè§‰å‡†å¤‡äº†ï¼Œé—®çš„å’Œåœ°ç†çš„åŸºæœ¬ä¸€æ ·ï¼Œæ•°å­—å°å˜äº†ä¸€ä¸‹ã€‚æ„Ÿæ…¨ä¸‹è‡ªå·±çš„æ•°å­¦è‹±è¯­çœŸæ˜¯æŠ“é¸¡ï¼Œä½œä¸ºç¬¬äºŒå¤©çš„ç¬¬ä¸€è½®ï¼Œè„‘å­éƒ½æ˜¯éº»çš„ã€‚å»ºè®®ä¸è¦åªçœ‹è¿‘æœŸçš„å¸¸è§é¢˜ï¼Œæœ€å¥½æŠŠ1-2å¹´çš„é¢˜å‹éƒ½è¿‡ä¸€ä¸‹ã€‚  

fake requestæ˜¯æ­£å¸¸request10å€é‚£ä¸ªconditional probabilityã€‚åæ¥åˆé—®äº†fraud detectç”¨æ¨¡å‹95%æ­£ç¡®ç‡ï¼Œå®é™…ç”±5%fraud accountï¼Œç®—é¢„æµ‹æ˜¯fraud å‰æä¸‹å®é™…ä¹Ÿæ˜¯fraudçš„æ¦‚ç‡ã€‚éƒ½æ˜¯åŸé¢˜ã€‚æœ€åæ€æ ·å†è¿›ä¸€æ­¥validateæ¨¡å‹é¢„æµ‹å‡ºæ¥çš„fraudçœŸçš„æ˜¯fraudã€‚åˆæ˜¯ab testé—®é¢˜ã€‚ã€‚


Below is a combined and reconstructed question contextâ€”plus the exact questions that were asked and detailed answersâ€”as they might appear during a Meta Data Scientist (Analytics Execution) interview round focused on probability, statistics, and tradeoff decisions for launching new features. This synthesis is based on the shared details from the original prompts.

## Context

You are interviewing for a Data Scientist (Analytics) position at Meta. One of the interview sections focuses on **Analytical Execution** questions, which typically cover:

1. Understanding hypotheses for launching new features.
2. Considering and quantifying tradeoffs in terms of metrics.
3. Elements of descriptive stats (mean, median, mode, percentiles, expected values).
4. Common distributions such as the binomial or the normal distribution.
5. Profile of real-world data (skew, outliers, large-scale data issues).
6. Law of Large Numbers, Central Limit Theorem, Linear Regression (basic conceptual understanding).
7. Conditional probabilities, including Bayesâ€™ Theorem.

**Note**: You will not be asked advanced math (e.g., calculus or advanced ML models), unusual distributions (e.g., exponential, Weibull, Beta), or â€œguesstimationâ€ questions.

**Scenario**: You are presented with a problem regarding fake accounts on a social network:
- **5% of all accounts are fake.**
- **Fake accounts send 10Ã— the number of friend requests compared to real (authentic) accounts.**

You are asked to compute probabilities and interpret a classifierâ€™s performance in detecting or blocking fake accounts.

---

## Exact Questions and Model Answers

### **Question 1**  
**What is the probability that a given friend request comes from a fake account?**

**Context/Hint Provided by Interviewer**:
- 5% of users are fake (prior = 0.05).
- Fake users send friend requests at 10Ã— the rate of real users.
- No other hidden assumptions or data.

**Answer Explanation**:
1. Define:
   - \( P(\text{Fake}) = 0.05 \): Proportion of fake users.
   - \( P(\text{Real}) = 0.95 \): Proportion of real users.
   - Let \( r \) be the baseline rate of friend requests sent by a real user.
   - Fake users send friend requests at a rate of \( 10r \).

2. Use Bayesâ€™ Theorem:
   \[
   P(\text{Fake | Request}) = \frac{P(\text{Fake}) \cdot P(\text{Request | Fake})}{P(\text{Fake}) \cdot P(\text{Request | Fake}) + P(\text{Real}) \cdot P(\text{Request | Real})}
   \]

3. Substitute rates:
- \( P(\text{FR} \mid \text{Fake}) \propto 10 \lambda_R \).
- \( P(\text{FR} \mid \text{Real}) \propto \lambda_R \).
4. Simplify:
   \[
   P(\text{Fake | Request}) = \frac{0.05 \cdot 10r}{0.05 \cdot 10r + 0.95 \cdot r} = \frac{0.5}{0.5 + 0.95} = \frac{0.5}{1.45} \approx 0.345
   \]

**Result**: ~34.5% of friend requests are from fake accounts, despite only 5% of users being fake.

---

### **Question 2**  
**What is the probability that, out of 5 received friend requests, at least one is from a fake account?**

**Context/Hint Provided by Interviewer**:
- Builds on Question 1: \( P(\text{Fake | Request}) \approx 0.345 \).
- Each friend request is an independent trial.

**Answer Explanation**:
1. Probability of no fake requests in 5 trials:
   \[
   P(\text{No Fake}) = (1 - 0.345)^5
   \]

2. Probability of at least one fake:
   \[
   P(\text{At Least One Fake}) = 1 - P(\text{No Fake})
   \]

3. Substituting \( P(\text{Fake | Request}) \):
   \[
   P(\text{At Least One Fake}) = 1 - (1 - 0.345)^5 \approx 1 - 0.659 \approx 0.879
   \]

**Result**: ~87.9% chance that at least one of 5 friend requests is from a fake account.

---

### **Question 3**  
**å‡å¦‚æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ª classification model æ¥è¯†åˆ« bad accountï¼Œåœ¨å»ºæ¨¡é˜¶æ®µæˆ‘ä»¬å‘ç°å®ƒçš„ True Positive Rate å’Œ True Negative Rate éƒ½æ˜¯ 95%ï¼Œé‚£ä¹ˆä¸€ä¸ªè¢«æ¨¡å‹åˆ¤æ–­ä¸º bad çš„ account å®ƒç¡®å®æ˜¯ bad çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿï¼ˆéœ€è¦ç”¨è´å¶æ–¯å…¬å¼ï¼‰**

---

**Answer Explanation**:

1. **Clarify Metrics**:
   - \( \text{True Positive Rate (TPR)} = 95\% \): The probability the model correctly identifies a bad account as bad.
   - \( \text{True Negative Rate (TNR)} = 95\% \): The probability the model correctly identifies a good account as good.
   - \( \text{False Positive Rate (FPR)} = 1 - \text{TNR} = 5\% \): The probability the model incorrectly identifies a good account as bad.
   - Let \( P(\text{Bad}) = p \) (prior probability of bad accounts), and \( P(\text{Good}) = 1 - p \).

2. **Bayesâ€™ Theorem**:
   To find \( P(\text{Bad} \mid \text{Model says Bad}) \):
   \[
   P(\text{Bad} \mid \text{Model says Bad}) = \frac{P(\text{Model says Bad} \mid \text{Bad}) \cdot P(\text{Bad})}{P(\text{Model says Bad})}.
   \]

   The total probability \( P(\text{Model says Bad}) \) is:
   \[
   P(\text{Model says Bad}) = P(\text{Model says Bad} \mid \text{Bad}) \cdot P(\text{Bad}) + P(\text{Model says Bad} \mid \text{Good}) \cdot P(\text{Good}).
   \]

3. **Substitute Values**:
   Substitute \( P(\text{Model says Bad} \mid \text{Bad}) = 0.95 \), \( P(\text{Model says Bad} \mid \text{Good}) = 0.05 \), and the priors:
   \[
   P(\text{Bad} \mid \text{Model says Bad}) = \frac{0.95p}{0.95p + 0.05(1 - p)}.
   \]

4. **Simplify**:
   \[
   P(\text{Bad} \mid \text{Model says Bad}) = \frac{0.95p}{0.9p + 0.05}.
   \]

5. **Example**:
   - Assume \( P(\text{Bad}) = 0.05 \) (5% of accounts are bad):
     \[
     P(\text{Bad} \mid \text{Model says Bad}) = \frac{0.95 \cdot 0.05}{0.9 \cdot 0.05 + 0.05} = \frac{0.0475}{0.045 + 0.05} = \frac{0.0475}{0.095} \approx 0.5.
     \]
   - The probability is **50%**, meaning that if the model flags an account as bad, thereâ€™s a 50% chance itâ€™s actually bad.

6. **Interpretation**:
   - **Imbalanced Data Impact**: Despite the model's high TPR and TNR, the low prevalence of bad accounts (\( P(\text{Bad}) = 0.05 \)) leads to a high number of false positives dominating the predictions.
   - **Precision Issue**: A 50% posterior probability indicates the classifier is only slightly better than random guessing for flagged accounts.

7. **Considerations for Improvement**:
   - Adjust the decision threshold to balance the False Positive Rate (FPR) and False Negative Rate (FNR).
   - Use secondary validation steps for flagged accounts to improve overall precision.
   - Consider the cost-benefit tradeoff of false positives versus false negatives when deciding to deploy the model.

### **Question 4**  
**What metrics or approach would you look at to decide if you should launch this classifier?**

**Answer Explanation**:
- **Metrics**:
  - Confusion Matrix: TPR, FPR, FNR, Precision, Recall, F1-score.
  - Precision-Recall tradeoff, especially in unbalanced data (5% fake accounts).
- **Cost-Based Metrics**:
  - Weigh the cost of false positives (e.g., user friction) vs. false negatives.
- **A/B Testing**:
  - Evaluate user impact (e.g., appeals, user churn) vs. fake account reduction.
- **ROC/PR Curves**:
  - Identify optimal thresholds.

**Summary**: Decisions must balance precision, recall, and user experience impact.

---

## Why These Questions Align with Metaâ€™s Analytical Execution

1. **Hypotheses**: You hypothesized friend request patterns and classifier performance.
2. **Tradeoffs**: Balanced false positives/negatives and user impact.
3. **Descriptive Stats**: Applied binomial assumptions and conditional probability.
4. **Bayesâ€™ Theorem**: Converted priors to actionable posteriors.
5. **Real-World Data Profile**: Explained disproportionate impact of fake accounts.

---

## Key Takeaways for Candidates

- **Clarify Priors**: Understand baseline rates and their implications.
- **Apply Bayes**: Practice converting accuracy metrics into real-world probabilities.
- **Balance Tradeoffs**: Evaluate costs/impacts for large-scale user bases.
- **Communicate Clearly**: Structure your assumptions, math, and conclusions.

By demonstrating probability skills, tradeoff analysis, and real-world impact considerations, you showcase the analytical execution skills Meta values.

**I. Identifying Fake Accounts and Content**

*   **Detection Methods:**
    *   How would you identify fake accounts on a platform like Facebook or Instagram? Consider user reports, registration information analysis (IP address, email, phone number), friend request patterns, or machine learning models.
    *   What specific features would you use in a model to detect fake accounts?
    *   How would you identify fake high school information on Facebook?
    *   How can you detect fake accounts via the long tail in the distribution, high post/day, or high median interval between posts?
    *  What other methods can be used to identify fake accounts?
    * How would you differentiate between fake news that looks exactly like real news?
    *   How would you use user comments as a signal to identify fake news?
    *   How would you detect and estimate the impact of fake accounts?
    * How would you evaluate a system for detecting spam accounts?
    *   What "long tail" characteristics would you look for when analyzing a distribution to find fake accounts?
*   **Evaluation of Flags:**
    *   A user's comment was flagged as fake. How would you evaluate the validity of this flag?
    *   A news article was flagged as fake. What kind of data is used to determine if the news is indeed fake?

**II. Measuring the Impact of Fake Accounts**

*   **Impact Metrics:**
    *   How do you measure the impact of fake accounts on the platform and on real users? Consider metrics like user engagement (DAU, time spent), user churn, content prevalence, and network effects.
    *   How would you evaluate the impact of fake accounts on "send friend request" behavior?
    *   How do fake accounts affect user engagement?
*   **Quantifying Impact:**
    *   There are 5% fake accounts on the platform. If a fake account sends friend requests 10 times more frequently than a real account, how would you calculate the probability that a friend request is from a fake account?
    *   How would you estimate the impact of fake news, and how could an intern help with this process?
    *   How would you estimate the impact of fake news within an 8-hour timeframe?
    *   How do you measure the impact of fake accounts, including network effects, user churn, and content prevalence?

**III. Detection and Mitigation Strategies**

*   **Handling Evasion:**
    * How do you deal with bad actors who know how to evade detection models?
    *   How would you evaluate users who are trying to avoid spam detection?
*   **Scaling Solutions:**
    *   How would you scale your fake account detection solution?
*  **Manual Review**
   * If there are a large number of fake accounts, how do you determine which ones to manually review? What attributes would you focus on?
*   **Mitigation:**
    *  How would you minimize fake profiles, possibly using 2-step verification for risky users?
*   **General Principles**
    *  The key with fraud is that it doesn't happen only once. People who commit fraud would like to repeat it if not being caught.

**IV. Modeling and Analysis**

*   **Model-Based Approaches:**
    *   How can you use a model to measure the impact of fake accounts?
    *   What kind of features would you include in the model, and why?
    *   How would you validate your model?
    *  If you don't have a model, what approach could you use?
    *  How would you build a model to predict fake news?
*   **Bayesian Methods**
     *   How to identify bad actors using Bayesian methods?
    *   How to calculate the probability of a user being a bad actor?
*   **Thresholds & Anomaly Detection**
      *  How would you use a threshold to identify abnormal data points to find fake accounts?
*    **Model Evaluation**:
     * Given a model that predicts fraud with 95% accuracy, and 5% of accounts are fraudulent, calculate the probability that a positive prediction is correct.
     *  How would you further validate the model and ensure that the predicted fraud is actually fraud?
*   **Statistical Analysis:**
    *  What metrics should you look at in an unbalanced dataset, such as one with a low percentage of fake accounts?
    *   Given a classifier with a 95% TP and FN rate, how do you evaluate it in the context of fake account detection? What metrics would you use, and why?
    *   How do you measure the false negatives and false positives in fake account detection? What if you do not have ground truth, or cannot build a model?

**V. Experimentation and Causal Inference**

*   **A/B Testing:**
    *  How would you set up an A/B test for fake account detection?
*   **Difference-in-Differences (DiD):**
    *   How would you use a Difference-in-Differences (DiD) approach to measure the impact of fake accounts?
    *   What kind of interaction point would you use for DiD?

These questions are designed to cover a range of concepts and skills related to fake accounts, including detection, impact measurement, mitigation, and model evaluation. They also incorporate various analytical and statistical methods, and encourage you to think critically and creatively.


# å‡æ–°é—»
# è¯„è®ºåˆ†å¸ƒ
### **Comment Distribution Question**

#### **Context**
The question was asked in the **Analytics Execution** portion of the Meta Data Scientist interview. It evaluates the candidateâ€™s understanding of data distributions, descriptive statistics, and their ability to hypothesize based on common patterns in user behavior.

The product in focus is a **newsfeed-like feature** where users can comment on posts. Candidates were asked to analyze the distribution of comments and perform statistical reasoning.

---

### **Question 1**  
**Describe the distribution of the number of comments per user in a newsfeed-like product. Draw the graph and indicate the mean, median, and the 95th percentile.**

**Answer Explanation**:
1. **Distribution Shape**:
   - The distribution is **zero-inflated and long-tailed**:
     - Most users make no comments (leading to a spike at zero).
     - Among users who do comment, the majority make few comments, but a small number of highly active users comment a lot, causing a long tail.

2. **Key Metrics**:
   - **Mean**: Positioned further toward the right, influenced by the long tail.
   - **Median**: Closer to the spike at zero, as the majority of users make no or few comments.
   - **95th Percentile**: Located further right, near the long tail, representing very active users.

3. **Visualization**:
   - The graph would show a large spike at zero, followed by a decreasing curve with a long right tail.

---

### **Question 2**  
**If users are randomly divided into groups of 10,000 users each and this process is repeated 200 times, what is the distribution of the average number of comments per group?**

**Answer Explanation**:
1. **Distribution Type**:
   - The resulting distribution is approximately **normal** due to the Central Limit Theorem (CLT), assuming the individual averages are based on sufficiently large samples (10,000 users per group).

2. **Key Characteristics**:
   - **Mean**: The mean of the distribution will be the population mean (e.g., 2 comments per user).
   - **Deviation**: The standard deviation depends on the **sample size** and the variability of the population distribution.

3. **Impact of Sample Size**:
   - Smaller group sizes lead to larger variability (wider distribution).
   - Larger group sizes reduce variability (narrower distribution).

---

### **Question 3**  
**If the average number of comments suddenly increases from 2 to 3, how would you analyze the causes?**

**Answer Explanation**:
1. **Internal Factors**:
   - **App changes**: Design updates or features that encourage commenting (e.g., engagement campaigns or incentives).
   - **Improved user experience**: Changes that make commenting easier.

2. **External Factors**:
   - **News events**: Major events prompting user discussions.
   - **Changes in user demographics**: More active users joining the platform.

3. **Additional Hypothesis**:
   - **Fake accounts**: The increase might be caused by an influx of fake accounts posting excessive comments.

---

### **Question 4**  
**If real accounts post an average of 2 comments per day and fake accounts post an average of 50 comments per day, and the platform average is 3 comments per day, what is the ratio of fake to real accounts?**

**Answer Explanation**:
1. **Equation**:
   \[
   \text{Total Comments} = 50 \cdot \text{Fake Accounts} + 2 \cdot \text{Real Accounts}
   \]
   \[
   \text{Total Accounts} = \text{Fake Accounts} + \text{Real Accounts}
   \]
   \[
   \frac{\text{Total Comments}}{\text{Total Accounts}} = 3
   \]

2. **Solve for Ratio**:
   Substitute into the equation:
   \[
   50 \cdot \text{Fake Accounts} + 2 \cdot \text{Real Accounts} = 3 \cdot (\text{Fake Accounts} + \text{Real Accounts})
   \]
   Simplify:
   \[
   47 \cdot \text{Fake Accounts} = \text{Real Accounts}
   \]

**Ratio**: \( 47:1 \).

---

### **Question 5**  
**Is it a good idea to ban accounts that post more than 50 comments daily to eliminate fake accounts?**

**Answer Explanation**:
1. **Short-term Feasibility**:
   - Effective in quickly reducing fake accounts, as most real users post far fewer than 50 comments per day.

2. **Long-term Concerns**:
   - Some real users might occasionally exceed 50 comments (e.g., during a major news event or personal activity).
   - Determined bad actors could adjust their behavior to evade detection.

3. **Recommended Approach**:
   - Combine threshold-based rules with **machine learning models** to detect fake accounts.
   - Use additional features (e.g., IP address patterns, activity timing) for robust identification.

---

### **Bonus Question**  
**If you track users from the long tail (high commenters) over time, where will their comment distribution trend?**

**Answer Explanation**:
1. **Mean Reversion**:
   - Over time, usersâ€™ activity levels tend to regress toward their personal average or the population mean.
   - Users from the long tail often include those who temporarily comment more than usual due to specific events.

2. **Assumption**:
   - Daily comment counts for each user are assumed to follow a stable distribution centered around their personal median.

3. **Conclusion**:
   - The long tail will likely shrink, and comment levels will trend toward the overall mean (e.g., 2 comments per user).

---

This set of questions comprehensively assesses the candidateâ€™s ability to analyze distributions, apply statistical reasoning, and make data-driven decisions while considering real-world complexities like user behavior and platform integrity.
[2024-12-10 Meta DSA VO é¢ç»](https://www.1point3acres.com/bbs/thread-1102145-1-1.html)  
å°è±¡éå¸¸æ·±åˆ»çš„ä¸€åœºï¼Œæ˜¯ä¸€ä¸ªç»å…¸é—®é¢˜
å¦‚æœæœ‰ä¸€ä¸ªèšåˆæ–°é—»ç½‘ç«™ï¼Œç”¨æˆ·å¯ä»¥é˜…è¯»æ–°é—»ä¸”å‘å¸ƒè¯„è®ºï¼Œé—®å¦‚æœXæ˜¯DAUï¼ŒYæ˜¯è¯„è®ºæ•°ï¼Œè¿™æ˜¯ä¸ªä»€ä¹ˆåˆ†å¸ƒï¼Ÿç”»å‡ºæ¥
ç­”æ¡ˆï¼šè¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„Zero-inflated log normal distributionï¼ŒåŸå› æ˜¯å¤§éƒ¨åˆ†æµè§ˆæ–°é—»çš„äººå¯èƒ½éƒ½ä¸ä¼šç•™ä¸‹æˆ–è€…å¾ˆå°‘ç•™ä¸‹è¯„è®ºï¼Œå› æ­¤ä¼šæœ‰å¾ˆå¤šçš„0ï¼Œç„¶ååœ¨ä¼šè¯„è®ºçš„äººé‡Œï¼Œå¤§éƒ¨åˆ†äººè¯„è®ºæ¯”è¾ƒå°‘ï¼Œå°‘éƒ¨åˆ†äººè¯„è®ºå¾ˆå¤šï¼Œå› æ­¤æœ‰ä¸€ä¸ªé•¿å°¾ã€‚å¤§æ¦‚å¦‚ä¸‹å›¾ï¼š  
![My Picture](images/distribution.png "My Picture")  


æˆ‘ç»™å‡ºçš„è¯„è®ºå¹³å‡æ•°å¤§æ¦‚æ˜¯2ï¼Œé¢è¯•å®˜è¯´é‚£å°±ç”¨è¿™ä¸ªæ•°å­—ã€‚
follow upï¼šå¦‚æœç°åœ¨éšæœºç»™ç”¨æˆ·åˆ†æ¡¶ï¼Œæ¯ä¸ªæ¡¶10K userï¼Œè®¡ç®—æ¯ä¸ªæ¡¶çš„è¯„è®ºå¹³å‡æ•°ï¼Œç„¶åè¿™ä¸ªå¹³å‡æ•°å¾—åˆ°çš„åˆ†å¸ƒæ˜¯ä»€ä¹ˆï¼Ÿ.
ç­”ï¼šsampling distributionï¼Œä¸€ä¸ªåæ­£æ€ï¼Œå¹³å‡å€¼æ˜¯2ï¼Œä½†æ˜¯é è¿‘åæ ‡åŸç‚¹æœ‰å‡¸èµ·ï¼ˆå› ä¸ºzero inflationï¼Œæ‰€ä»¥ä¼šæœ‰ä¸€å®šæ•°é‡çš„0ï¼‰çš„åˆ†å¸ƒã€‚
follow upï¼šæœ‰ä¸€å¤©ä½ å‘ç°è¯„è®ºæ•°å¤§å¤§æå‡äº†ï¼Œä»2åˆ°äº†3ï¼Œè¯·é—®ä½ å¦‚ä½•åˆ†æä¸ºä»€ä¹ˆï¼Ÿæˆ‘ä»å†…éƒ¨ï¼Œå¤–éƒ¨å› ç´ è¿›è¡Œäº†åˆ†æï¼Œä¾‹å¦‚appæ”¹ç‰ˆï¼Œengagement campaigné¼“åŠ±æ›´å¤šè¯„è®ºï¼Œé‡ç‚¹å¤–éƒ¨æ–°é—»äº‹ä»¶å‘ç”Ÿå¯¼è‡´è¯„è®ºç”¨æˆ·å¢åŠ ï¼Œæœ€åå¼•å¯¼åˆ°äº†fake accountã€‚
. 1point 3 acres
. .Ğ¸
follow upï¼šä¸€ä¸ªçœŸçš„accountæ¯æ—¥è¯„è®ºå¹³å‡æ•°æ˜¯2ï¼Œfake accountæ˜¯50ï¼Œç°åœ¨å¹³å°å¹³å‡è¯„è®ºæ˜¯3ï¼Œfake ï¼šrealçš„å¯¹æ¯”æ˜¯å¤šå°‘ï¼Ÿ
50fake + 2real = total comment
total account = fake + real
tc / ta = 3
(50fake + 2real) / (fake+real) = 3
50/3 fake + 2/3 real = fake + real. 1point3acres
47/3 fakeÂ Â = 1/3 real.googleÂ Â Ğ¸
ç­”æ¡ˆæ˜¯47:1
follow upï¼šç°åœ¨PMé—®ä½ ï¼Œæˆ‘ä»¬è¦è§£å†³fake accounté—®é¢˜ï¼Œæ‰€ä»¥è®¾ç«‹ä¸€ä¸ªè§„åˆ™ï¼Œæ—¥è¯„è®ºå¤§äº50ç»Ÿç»Ÿå°ç¦ï¼Œæ˜¯ä¸æ˜¯ä¸ªå¥½ä¸»æ„ï¼Ÿ
.1point3acres
ç­”ï¼šçŸ­æœŸï¼ˆ2-3æ—¥ï¼‰ï¼Œå¯ä»¥ï¼Œé•¿æœŸï¼Œä¸è¡Œï¼Œéœ€è¦exploreå…¶ä»–æ–¹æ¡ˆï¼Œä¾‹å¦‚æœºå™¨å­¦ä¹ é‰´åˆ«fake accountã€‚ä¸‹é¢å°±æ˜¯ä¸€ç³»åˆ—æœºå™¨å­¦ä¹ çš„æ¨¡å‹è®¾è®¡ï¼Œfeature selectionï¼Œground truthä»å“ªé‡Œæ¥ï¼Œå¦‚ä½•è·ŸPMæ²Ÿé€šåšæŠ‰æ‹©ï¼Œç­‰ç­‰çš„äº§å“å’Œæ²Ÿé€šé—®é¢˜ã€‚
.googleÂ Â Ğ¸
. 1point 3acres
bonus questionï¼šå¦‚æœæˆ‘ä»¬ä»åŸæœ¬è¯„è®ºçš„åˆ†å¸ƒé•¿å°¾ä¸Šå–å‡ºä¸€æ‰¹è¯„è®ºæ•°é‡é«˜çš„ç”¨æˆ·ï¼Œè¿½è¸ªå®ƒä»¬ä¸€æ®µæ—¶é—´ï¼Œä¸€æ®µæ—¶é—´åä»–ä»¬çš„åˆ†å¸ƒå¤§æ¦‚ç‡ä¼šåœ¨å“ªé‡Œï¼Ÿ.
. Î§
ç­”ï¼šåå‘å‡å€¼å›å½’ï¼Œå¯¹æ¯ä¸ªäººæ¥è¯´ï¼Œæ¯æ—¥çš„è¯„è®ºæ¦‚ç‡å¯ä»¥å‡è®¾å›ºå®šä¸”å›´ç»•ä¸ªäººä¸­å€¼åˆ†å¸ƒï¼Œé•¿å°¾ä¸Šå¾ˆæœ‰å¯èƒ½æ˜¯ä¾‹å¦‚æŸäº›äººæ°å¥½æŸå¤©è¯„è®ºæ•°ç‰¹åˆ«å¤š+ä¸€äº›æœ¬æ¥è¯„è®ºå°±å¾ˆå¤šäººçš„èšåˆï¼Œé•¿æœŸæ¥çœ‹ä¼šå‡å€¼å›å½’ã€‚

-----
# Feedé‡Œæ’å¹¿å‘Š
### **Ads Impression Distribution Question**

#### **Context**
The question was asked in the **Analytics Execution** portion of the Meta Data Scientist interview. It evaluates the candidate's understanding of **expected value**, **probability**, and **binomial distribution**, along with their ability to analyze ad impression data. The scenario involves impressions randomly distributed among users.

---

### **Question 1**  
**What is the expected number of ads seen by a user if an advertiser purchases \( A \) impressions for a target audience size of \( u \)?**

**Answer Explanation**:
1. **Probability of an impression reaching a specific user**:
   - \( P(\text{Impression for User}) = \frac{1}{u} \).

2. **Expected number of impressions for one user**:
   - \( \mathbb{E}[\text{Ads}] = A \cdot \frac{1}{u} = \frac{A}{u} \).

---

### **Question 2**  
**What is the probability of a user not seeing any ads?**

**Answer Explanation**:
1. **Binomial distribution for not seeing ads**:
   - \( P(\text{No Ads for User}) = \left(1 - \frac{1}{u}\right)^A \).


### **Question 3**  
**What is the probability of a user seeing at least one ad?**

**Answer Explanation**:
1. **Complement Rule**:
   - \( P(\text{At Least One Ad}) = 1 - P(\text{No Ads for User}) \).

2. **Substitute \( P(\text{No Ads for User}) \)**:
   - \( P(\text{At Least One Ad}) = 1 - \left(1 - \frac{1}{u}\right)^A \).

---

### **Question 4**  
**What is the expected number of users seeing at least one ad?**

**Answer Explanation**:
1. **Expected number of users**:
   - \( \mathbb{E}[\text{Users with Ads}] = u \cdot P(\text{At Least One Ad}) \).

2. **Substitute \( P(\text{At Least One Ad}) \)**:
   - \( \mathbb{E}[\text{Users with Ads}] = u \cdot \left[1 - \left(1 - \frac{1}{u}\right)^A\right] \).

---

### **Question 5**  
**If 25% of users are high-intent (90% click probability) and 75% are low-intent (10% click probability), what is the expected number of clicks for \( A \) impressions?**

**Answer Explanation**:
1. **Weighted Click Rate**:
   - \( \text{Click Rate} = 0.25 \cdot 0.9 + 0.75 \cdot 0.1 = 0.225 + 0.075 = 0.3 \).

2. **Expected Clicks**:
   - \( \mathbb{E}[\text{Clicks}] = A \cdot \text{Click Rate} \).

3. **Substitute**:
   - \( \mathbb{E}[\text{Clicks}] = 0.3 \cdot A \).

---

### **Question 6**  
**Draw a graph for the likelihood of zero clicks versus the number of impressions (\( A \)).**

**Answer Explanation**:
1. **Likelihood of Zero Clicks**:
   - For all impressions to result in no clicks:
     \[
     P(\text{Zero Clicks}) = \left(1 - \text{Click Rate}\right)^A.
     \]

2. **Substitute Click Rate**:
   - \( P(\text{Zero Clicks}) = \left(1 - 0.3\right)^A = 0.7^A \).

3. **Graph**:
   - \( x \)-axis: Number of impressions (\( A \)).
   - \( y \)-axis: \( P(\text{Zero Clicks}) = 0.7^A \), which decays exponentially.

---

### **Question 7**  
**The business wants to serve ads only to high-intent users. Is this a good idea?**

**Answer Explanation**:
1. **Short-term Feasibility**:
   - Focusing on high-intent users (\( 25\% \)) maximizes the click rate (0.9), increasing immediate returns.

2. **Long-term Concerns**:
   - Narrowing the target audience reduces overall reach and impressions, potentially leading to **saturation**.
   - Excluding low-intent users might harm brand awareness and future engagement.

3. **Recommendation**:
   - Combine targeting strategies:
     - Prioritize high-intent users for direct response campaigns.
     - Include low-intent users for broader brand awareness.
     
### Question 8: **Probability of Users Seeing Back-to-Back Ads**

The probability of users seeing back-to-back ads depends on the ad placement strategy (e.g., fixed interval vs. random insertion). Below is the calculation for both scenarios.

---

### **1. Scenario 1: Fixed Interval Ad Insertion**
If ads are inserted **every 20 users**:
- Ads are uniformly distributed across users, with no overlap between consecutive ads.
- **Probability of Back-to-Back Ads**:
  \[
  P(\text{Back-to-Back Ads}) = 0
  \]

---

### **2. Scenario 2: Random Ad Insertion**
If ads are randomly assigned with a probability \( p = 5\% \) to each user:

#### **Probability Calculation**
1. **Define Events**:
   - \( A_i \): User \( i \) is shown an ad.
   - \( A_{i+1} \): User \( i+1 \) is shown an ad.
   - Ads are assigned independently, with \( P(A_i) = 0.05 \).

2. **Back-to-Back Probability**:
   - The probability of two consecutive users seeing ads:
     \[
     P(\text{Back-to-Back Ads}) = P(A_i \cap A_{i+1}).
     \]
   - Since the events are independent:
     \[
     P(\text{Back-to-Back Ads}) = P(A_i) \cdot P(A_{i+1}) = 0.05 \cdot 0.05 = 0.0025 \, (0.25\%).
     \]

3. **For a Group of Users**:
   For \( N \) users, there are \( N-1 \) consecutive pairs. The probability of at least one pair seeing back-to-back ads is:
   \[
   P(\text{At Least One Back-to-Back Pair}) = 1 - P(\text{No Back-to-Back Pairs}),
   \]
   where:
   \[
   P(\text{No Back-to-Back Pairs}) = \left(1 - 0.0025\right)^{N-1}.
   \]

4. **Approximation for Large \( N \)**:
   Using the exponential approximation:
   \[
   P(\text{At Least One Back-to-Back Pair}) \approx 1 - e^{-0.0025 \cdot (N-1)}.
   \]

---

### **3. Example Calculation**
Suppose the total number of users \( N = 1000 \):
1. Probability of a single back-to-back pair:
   \[
   P(\text{Back-to-Back Ads for 1 Pair}) = 0.0025.
   \]

2. Probability of at least one back-to-back pair:
   \[
   P(\text{At Least One Back-to-Back Pair}) \approx 1 - e^{-0.0025 \cdot (1000-1)} = 1 - e^{-2.4975}.
   \]

3. Approximate Value:
   \[
   P(\text{At Least One Back-to-Back Pair}) \approx 1 - 0.0822 = 0.9178.
   \]

**Result**: For a group of 1000 users with ads randomly assigned at 5%, the probability of at least one pair of users seeing back-to-back ads is approximately **91.78%**.

---

### **4. Summary**

- **Fixed Interval Insertion**:
  - Ads are evenly spaced, so the probability of back-to-back ads is:
    \[
    P(\text{Back-to-Back Ads}) = 0
    \]

- **Random Insertion**:
  - For a single pair of users:
    \[
    P(\text{Back-to-Back Ads}) = 0.25\%.
    \]
  - For large groups, the probability of at least one back-to-back pair increases significantly. For \( N = 1000 \), it is approximately **91.78%**.

When choosing an ad insertion strategy, balancing user experience and ad distribution fairness is crucial. Random insertion might lead to more back-to-back ads, potentially harming user experience.
---

### **Takeaways**
This set of questions comprehensively evaluates:
1. **Probability Rules**:
   - Binomial distribution and complement rule for impressions.
2. **Expected Value**:
   - Calculating expected values for impressions, clicks, and reach.
3. **Strategic Analysis**:
   - Short-term vs. long-term impacts of targeting decisions.

Clear articulation of assumptions, precise use of formulas, and connecting mathematical insights to actionable recommendations are key to solving such problems.

[2024-3-16ä¹°å®ƒdsè¿‡ç»](https://www.1point3acres.com/bbs/thread-1053544-1-1.html)  
[2024-4-15 Meta DSA VO](https://www.1point3acres.com/bbs/thread-1061408-1-1.html)  
Assuming we have an advertiser purchasing ads on our platform. The target audience size is u and the advertiser purchased A impressions.
1. What is the expectation of seeing ads?Â Â 
probability of seeing ads = 1/u, expectation is np so A/u
. check 1point3acres for more.
1. What is the probability of users not seeing the ads? (1-1/u)^A
2. What is the probability of users at least seeing one ads? 1-P(not seeing ad) = 1- (1-1/u)^A
3. What is the expectation of not seeing the ads? E[X] = np = [1- (1-1/u)^A] u. 1point 3 acres
4. Probability of high intent users is 25%, low intent users is 75%, high intent user 0.9 click rate, low intent user 0.1 click rate. What is the expectation of clicking? A[0.25*0.9+0.75*0.1]
5. Please draw a graph of likelihood of 0 clicking versus number of impressions. Y = (0.25*0.1+0.75*0.9)^A draw this equation -baidu 1point3acres
6. The business only wants to place ads only to high intent users, is this a good idea?
Binomial problem needs to remember E[X] = np, Var[X] = np(1-p); . From 1point 3acres bbs
The multiplication rule of probability, the probability of occurrence of both the events A and B is equal to the product of the probability of B occurring and the conditional probability that event A occurring given that event B occurs.
Take away: remember to explain explicitly what concept you are using and what rules you are using.
.
Analyze launch a new strategy â€”> A/B testing

é—®äº†ä¸ªcomment distributionã€‚ä¼šé—®åˆ°central limit theorem, expected value, population sd vs. sample sd, 95% confidence intervalã€‚ä»¥åŠè¿™ä¸ªå¸–å­çš„åŸé¢˜ğŸ”—Â www.1point3acres.com
å…¶ä¸­è¿™ä¸ªå¸–å­ä¸­æˆ‘çœ‹åˆ°æœ‰äººè®¨è®ºexpected value æ˜¯ä¹˜ä»¥Aè¿˜æ˜¯uã€‚åº”è¯¥æ˜¯uï¼Œå› ä¸ºé¢è¯•é‡Œé—®çš„ä¸æ˜¯ä¸€ä¸ªç”¨æˆ·ï¼Œè€Œæ˜¯æ‰€æœ‰ç”¨æˆ·.


å¥½å¤šä¸ªå°é¢˜ï¼Œä»Central limit T å¼€å§‹ï¼Œé—®æœ€åŸºæœ¬çš„æ¦‚å¿µã€‚

é€‰äºº - 1000ä¸ªäººé‡Œé¢æœ‰æ”¾å›æŠ½å–ã€‚ 1. æ¯ä¸ªäººon avg. åœ¨å¤šå°‘æ¬¡æŠ½åˆ°ã€‚ 2. è¿ç»­10æ¬¡ä½ æ²¡è¢«æŠ½åˆ°çš„æ¦‚ç‡ã€‚. .Ğ¸

 IMPRESSIONS - X people, ä¸€å…±æœ‰Y Impressionéšæœºåˆ†é…ã€‚ 1) expected impression per audienceï¼Ÿ2) probability of each person have at least one impressionã€‚è¿˜é—®äº†è¿‘ä¼¼å€¼æ˜¯å¤šå°‘ï¼Œå¤šäºä¹‹å‰çœ‹äº†é¢ç»ï¼Œéœ€è¦æ³°å‹’å±•å¼€ 3) expected number of audience have at least one impression

 Weâ€™ve ran a prediction model and discovered 25\x of our audience is high intent (90\x probability of clicks) and 75\x are low intent (10\x clicks), how many clicks do we expect to see?â€¨æˆ‘çš„ç­”æ¡ˆæ˜¯0.3Nã€‚ã€‚ã€‚

   ä¸å¥½æ„æ€variance æˆ‘æœ‰ç‚¹è®°ä¸æ¸…äº† ä½†æ˜¯æˆ‘æƒ³å¤æ‚äº† å°±æ˜¯ä¸€é“å¾ˆç›´æˆªäº†å½“å‘Šè¯‰ä½ å¤šå°‘ä¸ªsample ä½ ç”¨æœ€åŸå§‹çš„å…¬å¼ç®—variance å°±å¥½äº†çš„ ä¸éœ€è¦è¯´ä»»ä½•çš„distributionï¼Œæœ€åbinomial çš„é‚£ä¸ªProbability of 0 impressions ä½ æŠŠbinomialçš„å…¬å¼å†™å‡ºæ¥å°±ä¼šå‘ç°æœ‰å¯ä»¥ç”¨åˆ°taylor æ¥ä¼°ç®— è¿™ä¸€é¢˜æˆ‘åœ¨é¢ç»é‡Œçœ‹åˆ°è¿‡ å‡è®¾M N éƒ½å¾ˆå¤§é‚£ä¹ˆ(1-1/M)^N å¯ä»¥çº¦ç­‰äº1-N/mAB test å°±æ˜¯å‘Šè¯‰äº†æˆ‘ä¸€ä¸ªç»“æœå°±æ˜¯screen time æ²¡æœ‰significant difference é—®æˆ‘å¯èƒ½æ˜¯å› ä¸ºä»€ä¹ˆï¼Œè²Œä¼¼æ²¡æœ‰é—®é“CIï¼Œç„¶åå°±é—®æˆ‘é‚£å¯ä»¥é€‰æ‹©åˆ«çš„ä»€ä¹ˆmetric ä»¥åŠå¦‚ä½•æ¥è®¾è®¡ä¸€ä¸ªæ›´å¥½çš„test

   Xä¸ªaudienceï¼Œ Y ä¸ªimpression éšæœºåˆ†é…

1. expected impression per audienceï¼Ÿ-Y/X

2. probability of each person have at least one impression - 1-(1-1/X)^Y

3. expected number of audience have impression - (1-(1-1/X)^Y)*X

quantitative æ˜¯è€ƒads impression è¿˜æœ‰ active user daily post çš„æ•°é‡åˆ†å¸ƒç”»å›¾

Â  Â Â  Â Â Â ads impression: there are x users, y ads, each ad can reach to each user with equal probability, then for a particular user, the expected number of ads and varianceã€‚è¿™ä¸ªå°±æ˜¯æ ¹æ®binomial distribution, E(X) = np = y*(1/x), Var(X) = np(1-p) = y*(1/x)*(1-1/x). .. 

Â  Â Â  Â  The probability that one user does see at least one ads. ä¹Ÿæ˜¯æ ¹æ®binomial distributionå’Œè¡¥é›†æ¦‚å¿µï¼ŒP(X>=1) = 1 - P(X=0) = 1 - (1 - 1/x)^yã€‚

N people M impression, å¹³å‡ä¸€ä¸ªä¼šæ”¶åˆ°å¤šå°‘ä¸ªimpressionçš„æœŸæœ›ï¼Œé—®ä½ çš„assumptionå¯ä»¥æˆç«‹ä¹ˆæ˜¯ç‹¬ç«‹äº‹ä»¶å—ï¼Œç„¶åç»™çœ‹äº†ä¸¤ä¸ªconfidence intervalè®©interpret

